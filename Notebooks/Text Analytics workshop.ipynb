{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/furqan/Desktop/python_work/AIMasterclass/Text analytics/Notebooks',\n",
       " '/home/furqan/.pyenv/versions/3.8.5/lib/python38.zip',\n",
       " '/home/furqan/.pyenv/versions/3.8.5/lib/python3.8',\n",
       " '/home/furqan/.pyenv/versions/3.8.5/lib/python3.8/lib-dynload',\n",
       " '',\n",
       " '/home/furqan/.pyenv/versions/jupyter3/lib/python3.8/site-packages',\n",
       " '/home/furqan/.pyenv/versions/jupyter3/lib/python3.8/site-packages/IPython/extensions',\n",
       " '/home/furqan/.ipython']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/furqan/Desktop/python_work/AIMasterclass/Text analytics/Notebooks',\n",
       " '/home/furqan/.pyenv/versions/3.8.5/lib/python38.zip',\n",
       " '/home/furqan/.pyenv/versions/3.8.5/lib/python3.8',\n",
       " '/home/furqan/.pyenv/versions/3.8.5/lib/python3.8/lib-dynload',\n",
       " '',\n",
       " '/home/furqan/.pyenv/versions/jupyter3/lib/python3.8/site-packages',\n",
       " '/home/furqan/.pyenv/versions/jupyter3/lib/python3.8/site-packages/IPython/extensions',\n",
       " '/home/furqan/.ipython']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First of all install this package for performing azure analytics.\n",
    "\n",
    "# !pip install --upgrade azure-ai-textanalytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = \"9b391a08b8c5459696ef684a0fd42684\"\n",
    "# endpoint = \"https://texttesttttt.cognitiveservices.azure.com/\"\n",
    "\n",
    "key = \"INSERT YOUR KEY HERE\"\n",
    "endpoint = \"INSERT YOUR ENDPOINT HERE\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authenticate the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<azure.ai.textanalytics._text_analytics_client.TextAnalyticsClient object at 0x7fe3ac607d30>\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "def authenticate_client():\n",
    "    ta_credential = AzureKeyCredential(key)\n",
    "    text_analytics_client = TextAnalyticsClient(\n",
    "            endpoint=endpoint, credential=ta_credential)\n",
    "    return text_analytics_client\n",
    "\n",
    "client = authenticate_client()\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Sentiment: positive\n",
      "Overall scores: positive=1.00; neutral=0.00; negative=0.00 \n",
      "\n",
      "Sentence: I had the best day of my life.\n",
      "Sentence 1 sentiment: positive\n",
      "Sentence score:\n",
      "Positive=1.00\n",
      "Neutral=0.00\n",
      "Negative=0.00\n",
      "\n",
      "Sentence: I wish you were there with me.\n",
      "Sentence 2 sentiment: neutral\n",
      "Sentence score:\n",
      "Positive=0.21\n",
      "Neutral=0.77\n",
      "Negative=0.02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sentiment_analysis_example(client):\n",
    "\n",
    "    documents = [\"I had the best day of my life. I wish you were there with me.\"]\n",
    "    response = client.analyze_sentiment(documents = documents)[0]\n",
    "    print(\"Document Sentiment: {}\".format(response.sentiment))\n",
    "    print(\"Overall scores: positive={0:.2f}; neutral={1:.2f}; negative={2:.2f} \\n\".format(\n",
    "        response.confidence_scores.positive,\n",
    "        response.confidence_scores.neutral,\n",
    "        response.confidence_scores.negative,\n",
    "    ))\n",
    "    for idx, sentence in enumerate(response.sentences):\n",
    "        print(\"Sentence: {}\".format(sentence.text))\n",
    "        print(\"Sentence {} sentiment: {}\".format(idx+1, sentence.sentiment))\n",
    "        print(\"Sentence score:\\nPositive={0:.2f}\\nNeutral={1:.2f}\\nNegative={2:.2f}\\n\".format(\n",
    "            sentence.confidence_scores.positive,\n",
    "            sentence.confidence_scores.neutral,\n",
    "            sentence.confidence_scores.negative,\n",
    "        ))\n",
    "          \n",
    "sentiment_analysis_example(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Sentiment: positive\n",
      "Overall scores: positive=1.00; neutral=0.00; negative=0.00 \n",
      "\n",
      "Sentence: You are such a cool person.\n",
      "Sentence 1 sentiment: positive\n",
      "Sentence score:\n",
      "Positive=0.99\n",
      "Neutral=0.01\n",
      "Negative=0.00\n",
      "\n",
      "Sentence: and I am quite lucky to have so many friends.\n",
      "Sentence 2 sentiment: positive\n",
      "Sentence score:\n",
      "Positive=1.00\n",
      "Neutral=0.00\n",
      "Negative=0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sentiment_analysis_example(client):\n",
    "\n",
    "    documents = [\"You are such a cool person. and I am quite lucky to have so many friends.\"]\n",
    "    response = client.analyze_sentiment(documents = documents)[0]\n",
    "    print(\"Document Sentiment: {}\".format(response.sentiment))\n",
    "    print(\"Overall scores: positive={0:.2f}; neutral={1:.2f}; negative={2:.2f} \\n\".format(\n",
    "        response.confidence_scores.positive,\n",
    "        response.confidence_scores.neutral,\n",
    "        response.confidence_scores.negative,\n",
    "    ))\n",
    "    for idx, sentence in enumerate(response.sentences):\n",
    "        print(\"Sentence: {}\".format(sentence.text))\n",
    "        print(\"Sentence {} sentiment: {}\".format(idx+1, sentence.sentiment))\n",
    "        print(\"Sentence score:\\nPositive={0:.2f}\\nNeutral={1:.2f}\\nNegative={2:.2f}\\n\".format(\n",
    "            sentence.confidence_scores.positive,\n",
    "            sentence.confidence_scores.neutral,\n",
    "            sentence.confidence_scores.negative,\n",
    "        ))\n",
    "          \n",
    "sentiment_analysis_example(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tip:\n",
    "\n",
    "#### In some cases it may be hard to disambiguate languages based on the input. You can use the country_hint parameter to specify a 2-letter country code. By default the API is using the \"US\" as the default countryHint, to remove this behavior you can reset this parameter by setting this value to empty string country_hint : \"\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language:  French\n"
     ]
    }
   ],
   "source": [
    "def language_detection_example(client):\n",
    "    try:\n",
    "        documents = [\"Ce document est rédigé en Français.\"]\n",
    "        response = client.detect_language(documents = documents, country_hint = '')[0]\n",
    "        print(\"Language: \", response.primary_language.name)\n",
    "\n",
    "    except Exception as err:\n",
    "        print(\"Encountered exception. {}\".format(err))\n",
    "language_detection_example(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entities:\n",
      "\n",
      "\tText: \t trip \tCategory: \t Event \tSubCategory: \t None \n",
      "\tConfidence Score: \t 0.61 \n",
      "\n",
      "\tText: \t Seattle \tCategory: \t Location \tSubCategory: \t GPE \n",
      "\tConfidence Score: \t 0.82 \n",
      "\n",
      "\tText: \t last week \tCategory: \t DateTime \tSubCategory: \t DateRange \n",
      "\tConfidence Score: \t 0.8 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def entity_recognition_example(client):\n",
    "\n",
    "    try:\n",
    "        documents = [\"I had a wonderful trip to Seattle last week.\"]\n",
    "        result = client.recognize_entities(documents = documents)[0]\n",
    "\n",
    "        print(\"Named Entities:\\n\")\n",
    "        for entity in result.entities:\n",
    "            print(\"\\tText: \\t\", entity.text, \"\\tCategory: \\t\", entity.category, \"\\tSubCategory: \\t\", entity.subcategory,\n",
    "                    \"\\n\\tConfidence Score: \\t\", round(entity.confidence_score, 2), \"\\n\")\n",
    "\n",
    "    except Exception as err:\n",
    "        print(\"Encountered exception. {}\".format(err))\n",
    "entity_recognition_example(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Furqan ali,\n",
    "COntactn no:03xxxxxxxxxx email:Furqan@reliefme.org address\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entities:\n",
      "\n",
      "\tText: \t Furqan \tCategory: \t Person \tSubCategory: \t None \n",
      "\tConfidence Score: \t 0.73 \n",
      "\n",
      "\tText: \t student \tCategory: \t PersonType \tSubCategory: \t None \n",
      "\tConfidence Score: \t 0.73 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def entity_recognition_example(client):\n",
    "\n",
    "    try:\n",
    "        documents = [\"Furqan is a good student of the class.\"]\n",
    "        result = client.recognize_entities(documents = documents)[0]\n",
    "\n",
    "        print(\"Named Entities:\\n\")\n",
    "        for entity in result.entities:\n",
    "            print(\"\\tText: \\t\", entity.text, \"\\tCategory: \\t\", entity.category, \"\\tSubCategory: \\t\", entity.subcategory,\n",
    "                    \"\\n\\tConfidence Score: \\t\", round(entity.confidence_score, 2), \"\\n\")\n",
    "\n",
    "    except Exception as err:\n",
    "        print(\"Encountered exception. {}\".format(err))\n",
    "entity_recognition_example(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entities:\n",
      "\n",
      "\tText: \t Aisha \tCategory: \t Person \tSubCategory: \t None \n",
      "\tConfidence Score: \t 0.93 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def entity_recognition_example(client):\n",
    "\n",
    "    try:\n",
    "        documents = [\"Aisha is playing with the hearts of people and she loves to travel\"]\n",
    "        result = client.recognize_entities(documents = documents)[0]\n",
    "\n",
    "        print(\"Named Entities:\\n\")\n",
    "        for entity in result.entities:\n",
    "            print(\"\\tText: \\t\", entity.text, \"\\tCategory: \\t\", entity.category, \"\\tSubCategory: \\t\", entity.subcategory,\n",
    "                    \"\\n\\tConfidence Score: \\t\", round(entity.confidence_score, 2), \"\\n\")\n",
    "\n",
    "    except Exception as err:\n",
    "        print(\"Encountered exception. {}\".format(err))\n",
    "entity_recognition_example(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linked Entities:\n",
      "\n",
      "\tName:  Altair 8800 \tId:  Altair 8800 \tUrl:  https://en.wikipedia.org/wiki/Altair_8800 \n",
      "\tData Source:  Wikipedia\n",
      "\tMatches:\n",
      "\t\tText: Altair 8800\n",
      "\t\tConfidence Score: 0.88\n",
      "\tName:  Bill Gates \tId:  Bill Gates \tUrl:  https://en.wikipedia.org/wiki/Bill_Gates \n",
      "\tData Source:  Wikipedia\n",
      "\tMatches:\n",
      "\t\tText: Bill Gates\n",
      "\t\tConfidence Score: 0.63\n",
      "\t\tText: Gates\n",
      "\t\tConfidence Score: 0.63\n",
      "\tName:  Paul Allen \tId:  Paul Allen \tUrl:  https://en.wikipedia.org/wiki/Paul_Allen \n",
      "\tData Source:  Wikipedia\n",
      "\tMatches:\n",
      "\t\tText: Paul Allen\n",
      "\t\tConfidence Score: 0.60\n",
      "\tName:  Microsoft \tId:  Microsoft \tUrl:  https://en.wikipedia.org/wiki/Microsoft \n",
      "\tData Source:  Wikipedia\n",
      "\tMatches:\n",
      "\t\tText: Microsoft\n",
      "\t\tConfidence Score: 0.55\n",
      "\t\tText: Microsoft\n",
      "\t\tConfidence Score: 0.55\n",
      "\tName:  April 4 \tId:  April 4 \tUrl:  https://en.wikipedia.org/wiki/April_4 \n",
      "\tData Source:  Wikipedia\n",
      "\tMatches:\n",
      "\t\tText: April 4\n",
      "\t\tConfidence Score: 0.32\n",
      "\tName:  BASIC \tId:  BASIC \tUrl:  https://en.wikipedia.org/wiki/BASIC \n",
      "\tData Source:  Wikipedia\n",
      "\tMatches:\n",
      "\t\tText: BASIC\n",
      "\t\tConfidence Score: 0.33\n"
     ]
    }
   ],
   "source": [
    "def entity_linking_example(client):\n",
    "\n",
    "    try:\n",
    "        documents = [\"\"\"Microsoft was founded by Bill Gates and Paul Allen on April 4, 1975, \n",
    "        to develop and sell BASIC interpreters for the Altair 8800. \n",
    "        During his career at Microsoft, Gates held the positions of chairman,\n",
    "        chief executive officer, president and chief software architect, \n",
    "        while also being the largest individual shareholder until May 2014.\"\"\"]\n",
    "        result = client.recognize_linked_entities(documents = documents)[0]\n",
    "\n",
    "        print(\"Linked Entities:\\n\")\n",
    "        for entity in result.entities:\n",
    "            print(\"\\tName: \", entity.name, \"\\tId: \", entity.data_source_entity_id, \"\\tUrl: \", entity.url,\n",
    "            \"\\n\\tData Source: \", entity.data_source)\n",
    "            print(\"\\tMatches:\")\n",
    "            for match in entity.matches:\n",
    "                print(\"\\t\\tText:\", match.text)\n",
    "                print(\"\\t\\tConfidence Score: {0:.2f}\".format(match.confidence_score))\n",
    "            \n",
    "    except Exception as err:\n",
    "        print(\"Encountered exception. {}\".format(err))\n",
    "entity_linking_example(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linked Entities:\n",
      "\n",
      "\tName:  Pakistan \tId:  Pakistan \tUrl:  https://en.wikipedia.org/wiki/Pakistan \n",
      "\tData Source:  Wikipedia\n",
      "\tMatches:\n",
      "\t\tText: Pakistan's\n",
      "\t\tConfidence Score: 0.34\n",
      "\tName:  Karachi \tId:  Karachi \tUrl:  https://en.wikipedia.org/wiki/Karachi \n",
      "\tData Source:  Wikipedia\n",
      "\tMatches:\n",
      "\t\tText: Karachi\n",
      "\t\tConfidence Score: 0.21\n",
      "\tName:  Apple Inc. \tId:  Apple Inc. \tUrl:  https://en.wikipedia.org/wiki/Apple_Inc. \n",
      "\tData Source:  Wikipedia\n",
      "\tMatches:\n",
      "\t\tText: Apple\n",
      "\t\tConfidence Score: 0.17\n",
      "\tName:  Steve Jobs \tId:  Steve Jobs \tUrl:  https://en.wikipedia.org/wiki/Steve_Jobs \n",
      "\tData Source:  Wikipedia\n",
      "\tMatches:\n",
      "\t\tText: Steve\n",
      "\t\tConfidence Score: 0.16\n"
     ]
    }
   ],
   "source": [
    "def entity_linking_example(client):\n",
    "\n",
    "    try:\n",
    "        documents = [\"\"\"Apple was founded by Steve. Furqan ali is the biggest fan of steve jobs. \n",
    "                     You can't hide the truth that Pakistan's city Karachi is sinking.\"\"\"]\n",
    "        result = client.recognize_linked_entities(documents = documents)[0]\n",
    "\n",
    "        print(\"Linked Entities:\\n\")\n",
    "        for entity in result.entities:\n",
    "            print(\"\\tName: \", entity.name, \"\\tId: \", entity.data_source_entity_id, \"\\tUrl: \", entity.url,\n",
    "            \"\\n\\tData Source: \", entity.data_source)\n",
    "            print(\"\\tMatches:\")\n",
    "            for match in entity.matches:\n",
    "                print(\"\\t\\tText:\", match.text)\n",
    "                print(\"\\t\\tConfidence Score: {0:.2f}\".format(match.confidence_score))\n",
    "            \n",
    "    except Exception as err:\n",
    "        print(\"Encountered exception. {}\".format(err))\n",
    "\n",
    "entity_linking_example(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key phrase extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tKey Phrases:\n",
      "\t\t cat\n",
      "\t\t veterinarian\n"
     ]
    }
   ],
   "source": [
    "def key_phrase_extraction_example(client):\n",
    "\n",
    "    try:\n",
    "        documents = [\"My cat might need to see a veterinarian.\"]\n",
    "\n",
    "        response = client.extract_key_phrases(documents = documents)[0]\n",
    "\n",
    "        if not response.is_error:\n",
    "            print(\"\\tKey Phrases:\")\n",
    "            for phrase in response.key_phrases:\n",
    "                print(\"\\t\\t\", phrase)\n",
    "        else:\n",
    "            print(response.id, response.error)\n",
    "\n",
    "    except Exception as err:\n",
    "        print(\"Encountered exception. {}\".format(err))\n",
    "        \n",
    "key_phrase_extraction_example(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tKey Phrases:\n",
      "\t\t best cook\n",
      "\t\t furqan ali\n",
      "\t\t area\n",
      "\t\t Infact\n",
      "\t\t truth\n",
      "\t\t egg\n"
     ]
    }
   ],
   "source": [
    "def key_phrase_extraction_example(client):\n",
    "\n",
    "    try:\n",
    "        documents = [\"My name is furqan ali and I am the best cook in the area. Infact the truth is I don't know how to boil even an egg.\"]\n",
    "\n",
    "        response = client.extract_key_phrases(documents = documents)[0]\n",
    "\n",
    "        if not response.is_error:\n",
    "            print(\"\\tKey Phrases:\")\n",
    "            for phrase in response.key_phrases:\n",
    "                print(\"\\t\\t\", phrase)\n",
    "        else:\n",
    "            print(response.id, response.error)\n",
    "\n",
    "    except Exception as err:\n",
    "        print(\"Encountered exception. {}\".format(err))\n",
    "        \n",
    "key_phrase_extraction_example(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
